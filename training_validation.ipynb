{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eaa547e-a54b-487b-9195-db69c6880f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm as base_tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics.segmentation import DiceScore, MeanIoU\n",
    "from torchmetrics.classification import BinaryF1Score, BinaryJaccardIndex\n",
    "\n",
    "from bdd_100k_dataset_local import BDD100KDatasetLocal\n",
    "from model import SmallUNet\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03352dcd-a44f-48db-b419-7eb8d44a393a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_local() -> pd.DataFrame:\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    train_dataset_bdd = BDD100KDatasetLocal(\n",
    "        images_dir='./copied/Dataset/100k_images_train/bdd100k/images/100k/train',\n",
    "        masks_dir='./copied/Dataset/bdd100k_lane_labels_trainval/bdd100k/labels/lane/masks/train',\n",
    "        transform=transform,\n",
    "    )\n",
    "    val_dataset_bdd = BDD100KDatasetLocal(\n",
    "        images_dir='./copied/Dataset/100k_images_val/bdd100k/images/100k/val',\n",
    "        masks_dir='./copied/Dataset/bdd100k_lane_labels_trainval/bdd100k/labels/lane/masks/val',\n",
    "        transform=transform\n",
    "    )\n",
    "    test_dataset = BDD100KDatasetLocal(\n",
    "        images_dir='./copied/Dataset/100k_images_test/bdd100k/images/100k/test',\n",
    "        masks_dir='./copied/Dataset/bdd100k_lane_labels_trainval/bdd100k/labels/lane/masks/test',\n",
    "        transform=transform\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset_bdd, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset_bdd, batch_size=16, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "class BCEDiceLoss(nn.Module):\n",
    "    def __init__(self, bce_weight=0.5, pos_weight=None):\n",
    "        super().__init__()\n",
    "        self.bce = nn.BCEWithLogitsLoss(pos_weight=pos_weight) if pos_weight is not None else nn.BCEWithLogitsLoss()\n",
    "        self.bce_weight = bce_weight\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        bce_loss = self.bce(preds, targets)\n",
    "\n",
    "        preds = torch.sigmoid(preds)  # Convert logits to probabilities for Dice\n",
    "    \n",
    "        smooth = 1e-6\n",
    "        preds_flat = preds.view(-1)\n",
    "        targets_flat = targets.view(-1)\n",
    "\n",
    "        intersection = (preds_flat * targets_flat).sum()\n",
    "        dice_loss = 1 - (2 * intersection + smooth) / (preds_flat.sum() + targets_flat.sum() + smooth)\n",
    "\n",
    "        return self.bce_weight * bce_loss + (1 - self.bce_weight) * dice_loss\n",
    "\n",
    "def plot_and_save_curve(values, title, ylabel, filename):\n",
    "    plt.figure()\n",
    "    plt.plot(values)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_with_mean_curve(values1, values2, label1, label2, title, ylabel, filename):\n",
    "    mean_values = [(v1 + v2) / 2 for v1, v2 in zip(values1, values2)]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(values1, label=label1)\n",
    "    plt.plot(values2, label=label2)\n",
    "    plt.plot(mean_values, label='Mean', linestyle='--')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(filename)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5e0ef3-a8f8-4937-8653-4b817d27d433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=25, model_path='unet_lane_detection.pth', start_epoch=0):\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "    dice_history_lane = []\n",
    "    iou_history_lane = []\n",
    "    dice_history_bg = []\n",
    "    iou_history_bg = []\n",
    "    \n",
    "    patience = 3\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    val_dice_lane = 0\n",
    "    val_iou_lane = 0\n",
    "    val_dice_bg = 0\n",
    "    val_iou_bg = 0\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "\n",
    "        train_loader_tqdm = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\")\n",
    "        for images, masks in train_loader_tqdm:\n",
    "\n",
    "            images = images.cuda()\n",
    "            masks = masks.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            train_loader_tqdm.set_postfix({'Loss': train_loss / len(train_loader.dataset)})\n",
    "\n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        # Lane class (positive class = 1)\n",
    "        dice_lane = BinaryF1Score().to(device)\n",
    "        iou_lane = BinaryJaccardIndex().to(device)\n",
    "        \n",
    "        # Background class (positive class = 0) - invert predictions and targets\n",
    "        dice_bg = BinaryF1Score().to(device)\n",
    "        iou_bg = BinaryJaccardIndex().to(device)\n",
    "\n",
    "        val_loader_tqdm = tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} - Validation', mininterval=3.0)\n",
    "        with torch.no_grad():\n",
    "            for images, masks in val_loader_tqdm:\n",
    "\n",
    "                images = images.cuda()\n",
    "                masks = masks.cuda()\n",
    "\n",
    "                outputs = model(images)\n",
    "\n",
    "                loss = criterion(outputs, masks)\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "\n",
    "                #apply sigmoid for dice and iou calculations\n",
    "                outputs = torch.sigmoid(outputs)\n",
    "\n",
    "                # Threshold model output\n",
    "                preds = outputs\n",
    "                targets = masks\n",
    "                preds_bin = (preds > 0.5).int()\n",
    "\n",
    "                # LANE: positive = 1\n",
    "                dice_lane.update(preds_bin, masks)\n",
    "                iou_lane.update(preds_bin, masks)\n",
    "        \n",
    "                # BACKGROUND: invert\n",
    "                dice_bg.update(1 - preds_bin, 1 - masks)\n",
    "                iou_bg.update(1 - preds_bin, 1 - masks)\n",
    "\n",
    "                val_loader_tqdm.set_postfix({\n",
    "                    'Loss': val_loss / len(val_loader.dataset),\n",
    "                    # 'Dice Lane': val_dice_lane / no_batches,\n",
    "                    # 'IoU Lane': val_iou_lane / no_batches,\n",
    "                    'Dice Lane': dice_lane.compute().item(),\n",
    "                    'IoU Lane': iou_lane.compute().item()\n",
    "                })\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        \n",
    "        val_dice_lane = dice_lane.compute().item()\n",
    "        val_iou_lane = iou_lane.compute().item()\n",
    "        val_dice_bg = dice_bg.compute().item()\n",
    "        val_iou_bg = iou_bg.compute().item()\n",
    "\n",
    "        train_loss_history.append(train_loss)\n",
    "        val_loss_history.append(val_loss)\n",
    "        dice_history_lane.append(val_dice_lane)\n",
    "        iou_history_lane.append(val_iou_lane)\n",
    "        dice_history_bg.append(val_dice_bg)\n",
    "        iou_history_bg.append(val_iou_bg)\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        tqdm.write(f'Epoch {epoch+1}/{num_epochs}, '\n",
    "            f'Train Loss: {train_loss:.4f}, '\n",
    "            f'Val Loss: {val_loss:.4f}, '\n",
    "            f'Dice Lane: {val_dice_lane:.4f}, '\n",
    "            f'IoU Lane: {val_iou_lane:.4f}, '\n",
    "            f'Dice Bg: {val_dice_bg:.4f}, '\n",
    "            f'IoU Bg: {val_iou_bg:.4f}'\n",
    "        )\n",
    "\n",
    "        # Save the best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            \n",
    "            epochs_without_improvement = 0\n",
    "\n",
    "            if model_path != None:\n",
    "                torch.save({\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'epoch': epoch\n",
    "                }, model_path)\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "    os.makedirs(\"./metrics\", exist_ok=True)\n",
    "\n",
    "    plot_and_save_curve(train_loss_history, \"Training Loss\", \"Loss\", \"./metrics/train_loss.png\")\n",
    "    plot_and_save_curve(val_loss_history, \"Validation Loss\", \"Loss\", \"./metrics/val_loss.png\")\n",
    "    plot_and_save_curve(dice_history_lane, \"Lane Line Dice Score\", \"Dice\", \"./metrics/dice_score_lane.png\")\n",
    "    plot_and_save_curve(iou_history_lane, \"Lane Line IoU Score\", \"IoU\", \"./metrics/iou_score_lane.png\")\n",
    "    plot_and_save_curve(dice_history_bg, \"Background Dice Score\", \"Dice\", \"./metrics/dice_score_bg.png\")\n",
    "    plot_and_save_curve(iou_history_bg, \"Background IoU Score\", \"IoU\", \"./metrics/iou_score_bg.png\")\n",
    "\n",
    "    plot_with_mean_curve(dice_history_lane, dice_history_bg, \"Lane\", \"Background\", \"Dice Score\", \"Dice\", \"./metrics/dice_score_all.png\")\n",
    "    plot_with_mean_curve(iou_history_lane, iou_history_bg, \"Lane\", \"Background\", \"IoU Score\", \"IoU\", \"./metrics/iou_score_all.png\")\n",
    "\n",
    "    return dice_lane.compute().item()\n",
    "\n",
    "\n",
    "def start_training():\n",
    "    # pretrained_model = './best_smallunet_lane_detection.pth'\n",
    "    # model.load_state_dict(torch.load(pretrained_model, map_location=device, weights_only=True)['model_state_dict'])\n",
    "\n",
    "    save_model_path = './best_smallunet_lane_detection_20.pth'\n",
    "    model = SmallUNet(in_channels=3, out_channels=1, base_dropout=0.07574735102229871).cuda()\n",
    "    \n",
    "    # Criterion and optimizer setup\n",
    "    # criterion = nn.BCELoss()\n",
    "    # criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    \n",
    "    lane_weight = 6.767409237000989\n",
    "    pos_weight = torch.tensor([lane_weight]).to(device)\n",
    "    criterion = BCEDiceLoss(bce_weight=0.29775550050971283, pos_weight=pos_weight)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0014768215380281198)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "\n",
    "    train_loader, val_loader, _ = load_data_local()\n",
    "    train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=20, model_path=save_model_path)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    pretrained_model = './best_smallunet_lane_detection.pth'\n",
    "    \n",
    "    # Suggest hyperparameters to try\n",
    "    bce_weight = trial.suggest_float(\"bce_weight\", 0.1, 1.0)\n",
    "    lane_weight = trial.suggest_float(\"lane_weight\", 1.0, 20.0)\n",
    "    base_dropout = trial.suggest_float(\"base_dropout\", 0.05, 0.3)    \n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
    "    \n",
    "    # Model setup\n",
    "    model = SmallUNet(in_channels=3, out_channels=1, base_dropout=base_dropout).to(device)\n",
    "    model.load_state_dict(torch.load(pretrained_model, map_location=device, weights_only=True)['model_state_dict'])\n",
    "\n",
    "    pos_weight = torch.tensor([lane_weight]).to(device)\n",
    "    criterion = BCEDiceLoss(bce_weight=bce_weight, pos_weight=pos_weight)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "\n",
    "    # Load data\n",
    "    train_loader, val_loader, _ = load_data_local()\n",
    "\n",
    "    # Train and get best validation loss\n",
    "    dice_score = train_model(\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        num_epochs=5,  # shorter runs while searching\n",
    "        model_path=None,\n",
    "    )\n",
    "\n",
    "    return dice_score\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_training()\n",
    "    print(\"Hello from cluster\")\n",
    "    \n",
    "    # study = optuna.create_study(direction=\"maximize\")\n",
    "    # study.optimize(objective, n_trials=20)\n",
    "\n",
    "    # print(\"Best trial:\")\n",
    "    # print(study.best_trial)\n",
    "    # print(\"âœ… Best params:\", study.best_params)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
